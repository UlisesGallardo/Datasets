# -*- coding: utf-8 -*-
"""Tourist recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a8JwwCAdvhSm6LlDQ35GSaV0oqNrzukT

# Imports
"""

import pandas as pd
import numpy as np
import seaborn as sns
import re
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, f1_score
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.multiclass import OneVsRestClassifier

"""# Data"""

url = 'https://raw.githubusercontent.com/UlisesGallardo/Datasets/main/rest-mex_2022_recommendation_data_training/rest-mex_2022_recommendation_data_training.csv'
DF = pd.read_csv(url)
DF['Date'] = DF['Date'].apply(lambda x: x.split(" ")[0])
DF

url = 'https://raw.githubusercontent.com/UlisesGallardo/Datasets/main/rest-mex_2022_recommendation_data_test/rest-mex_2022_recomendation_data_test.csv'
Df_test = pd.read_csv(url)
Df_test

url = 'https://raw.githubusercontent.com/UlisesGallardo/Datasets/main/rest-mex_2022_recommendation_data_training/places_description.csv'
Lugares = pd.read_csv(url)
Lugares

"""# EDA"""

def H(x):
    M = len(x)
    values,counts = np.unique(x,return_counts=True)
    PX = counts/M
    h = - np.sum(PX * np.log2(PX)) #Entropía
        
    ncategories = len(values)
    hmax = -np.log2(1/ncategories) #Entropía máxima
    
    return h, hmax

def MI(x,y):
    Hx = H(x)[0]
    Hy = H(y)[0]
    Hxy = H(np.concatenate([x,y]))[0]

    MIxy = Hx + Hy - Hxy
    return  MIxy

"""## Entropy"""

entropy = np.zeros((len(DF.columns),2))
for i,column in enumerate(DF.columns):
    entropy[i] = H(DF[column])
    print(column,'\nEntropy:',entropy[i][0],'\nMax entropy:',entropy[i][1],'\n',entropy[i][0]/entropy[i][1],'\n')

"""## Mutual information"""

mutual_information = np.zeros((len(DF.columns),len(DF.columns)))
for i,row in enumerate(DF.columns):
    for j,column in enumerate(DF.columns):
        mutual_information[i][j] = (2*MI(DF[row].astype(str),DF[column].astype(str)))/(H(DF[row].astype(str))[0] + H(DF[column].astype(str))[0])

mutual_information = pd.DataFrame(mutual_information,columns=DF.columns,index=DF.columns)
print(mutual_information)

"""## Countplots"""

for feature in DF.columns: 
    if(feature!= "Index"):
      fig, axes = plt.subplots(figsize=(15, 15))
      plt.title(feature)
      sns.countplot(y = DF[feature].values)

"""# Models

## Imports
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

"""## Data"""

tipoLugar = []
for lugar in DF['Place'].values:
  i=Lugares[Lugares['Lugar']==lugar]['TipoLugar'].tolist()[0]
  tipoLugar.append(i)
DF['TipoLugar'] = tipoLugar

DF

scale_mapper = {"enero":0, "febrero":1, "marzo":2, "abril":3, "mayo":4,	"junio":5,	"julio":6,	"agosto":7,	"septiembre":8,	"octubre":9, "noviembre":10,	"diciembre":11, "desconocido":-1}
DF['Date'] = DF['Date'].replace(scale_mapper)

one_hot_data = pd.get_dummies(DF[['Gender','Place','Location', 'Type','TipoLugar']],drop_first=True)

DF2 = pd.DataFrame(one_hot_data)
DF3 = pd.DataFrame(DF['Date'])
new_DF = pd.concat([DF2, DF3], axis=1)

Xtrain, Xtest, Ytrain, Ytest = train_test_split(new_DF, DF['Label'] , random_state = 0, test_size = 0.31)

new_DF.shape

"""## Train and Metrics"""

dt = DecisionTreeClassifier()
# dt.fit(one_hot_data, DF['Label'])
dt.fit(Xtrain, Ytrain)
Ydt_predicted = dt.predict(Xtest)

print("Accuracy", accuracy_score(Ytest,Ydt_predicted))
print("F1", f1_score(Ytest,Ydt_predicted, average='macro'))

def displaymetrics(models_names: list, models: list, X_train: np.array, X_test: np.array, Y_train: np.array, Y_test: np.array):
    n = len(models)
    m = 3
    results = np.zeros((n, m))
    for index, model in enumerate(models): 
        model.fit(X_train, Y_train)
        Ypredicted = model.predict(Xtest)
        results[index][0] = accuracy_score(Ytest, Ypredicted)
        results[index][1] = f1_score(Ytest,Ypredicted,average='macro')
        results[index][2] = mean_absolute_error(Ytest, Ypredicted)

    return results

Models = [DecisionTreeClassifier(), SVC(C = 100, kernel = 'rbf', random_state=0), LogisticRegression() , RandomForestClassifier(max_depth=14)]
Name = ["Decision Tree", "SVC", "Logistic Regression", "Random Forest"]
results = displaymetrics(Name, Models, Xtrain, Xtest, Ytrain, Ytest)
Table = pd.DataFrame(results, index = Name, columns = ["Accuracy", "F1 score","MAE"])
Table